# 09_Runbook.md

## ìš´ì˜ ì ˆì°¨ì„œ (Operations Runbook)

### ìš´ì˜ ì ˆì°¨ ê°œìš” (Operations Procedure Overview)

KIS_CORE_V3 ìš´ì˜ ì ˆì°¨ëŠ” 5ë‹¨ê³„ ë°©ë²•ë¡ ì„ ë”°ë¦…ë‹ˆë‹¤: **PRE-FLIGHT â†’ PLAN â†’ ACT â†’ TEST â†’ REPORT**. ì´ ì²´ê³„ì  ì ‘ê·¼ë²•ì„ í†µí•´ ì•ˆì •ì ì´ê³  ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì‹œìŠ¤í…œ ìš´ì˜ì„ ë³´ì¥í•©ë‹ˆë‹¤.

### ì ˆì°¨ íë¦„ë„ (Procedure Flow)

```mermaid
graph TD
    A[PRE-FLIGHT] --> B[PLAN]
    B --> C[ACT]
    C --> D[TEST]
    D --> E[REPORT]
    E --> F{Success?}
    F -->|Yes| G[Complete]
    F -->|No| H[Rollback]
    H --> B
    
    A1[í™˜ê²½ ì ê²€] --> A
    A2[ì˜ì¡´ì„± í™•ì¸] --> A
    A3[ë°±ì—… ìƒì„±] --> A
    
    B1[ì‘ì—… ê³„íš] --> B
    B2[ë¦¬ìŠ¤í¬ ë¶„ì„] --> B
    B3[ìŠ¹ì¸ íšë“] --> B
    
    C1[ë³€ê²½ ì‹¤í–‰] --> C
    C2[ëª¨ë‹ˆí„°ë§] --> C
    C3[ë¡œê·¸ ìˆ˜ì§‘] --> C
    
    D1[ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸] --> D
    D2[ì„±ëŠ¥ í…ŒìŠ¤íŠ¸] --> D
    D3[íšŒê·€ í…ŒìŠ¤íŠ¸] --> D
    
    E1[ê²°ê³¼ ë¶„ì„] --> E
    E2[ë¬¸ì„œ ì—…ë°ì´íŠ¸] --> E
    E3[ì´í•´ê´€ê³„ì í†µë³´] --> E
```

## PHASE 1: PRE-FLIGHT (ì‚¬ì „ ì ê²€)

### 1.1 í™˜ê²½ ì ê²€ (Environment Check)

#### ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸ (System Health Check)
```bash
#!/bin/bash
# preflight-system-check.sh

echo "=== KIS_CORE_V3 PRE-FLIGHT CHECK ==="
echo "Timestamp: $(date -u)"
echo "Operator: $(whoami)"
echo "Environment: ${ENVIRONMENT:-production}"
echo

# 1. ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
echo "1. Service Status Check"
echo "------------------------"
services=("api-gateway" "estimator-service" "erp-ai-service" "postgresql" "redis")
for service in "${services[@]}"; do
    if systemctl is-active --quiet $service; then
        echo "âœ… $service: RUNNING"
    else
        echo "âŒ $service: STOPPED"
        exit 1
    fi
done

# 2. ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ í™•ì¸
echo -e "\n2. Resource Usage Check"
echo "------------------------"
cpu_usage=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1)
memory_usage=$(free | grep Mem | awk '{printf "%.1f", $3/$2 * 100.0}')
disk_usage=$(df -h / | awk 'NR==2 {print $5}' | cut -d'%' -f1)

echo "CPU Usage: ${cpu_usage}%"
echo "Memory Usage: ${memory_usage}%"
echo "Disk Usage: ${disk_usage}%"

# ì„ê³„ì¹˜ í™•ì¸
if (( $(echo "$cpu_usage > 80" | bc -l) )); then
    echo "âš ï¸  WARNING: High CPU usage"
fi
if (( $(echo "$memory_usage > 85" | bc -l) )); then
    echo "âš ï¸  WARNING: High memory usage"
fi
if [ "$disk_usage" -gt 90 ]; then
    echo "âš ï¸  WARNING: High disk usage"
fi

# 3. ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
echo -e "\n3. Network Connectivity Check"
echo "-------------------------------"
endpoints=("https://api.kis-core.com/health" "postgresql://localhost:5432" "redis://localhost:6379")
for endpoint in "${endpoints[@]}"; do
    if curl -s --connect-timeout 5 "$endpoint" > /dev/null 2>&1; then
        echo "âœ… $endpoint: REACHABLE"
    else
        echo "âŒ $endpoint: UNREACHABLE"
    fi
done

echo -e "\n=== PRE-FLIGHT CHECK COMPLETE ==="
```

#### ì˜ì¡´ì„± í™•ì¸ (Dependencies Check)
```bash
#!/bin/bash
# preflight-dependencies.sh

echo "=== DEPENDENCIES CHECK ==="

# 1. ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
echo "1. Database Connection"
echo "----------------------"
psql -h localhost -U kis_user -d kis_db -c "SELECT version();" > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… PostgreSQL: CONNECTED"
else
    echo "âŒ PostgreSQL: CONNECTION FAILED"
    exit 1
fi

# 2. ìºì‹œ ì„œë²„ í™•ì¸
echo -e "\n2. Cache Server"
echo "---------------"
redis-cli ping > /dev/null 2>&1
if [ $? -eq 0 ]; then
    echo "âœ… Redis: CONNECTED"
else
    echo "âŒ Redis: CONNECTION FAILED"
    exit 1
fi

# 3. ì™¸ë¶€ API í™•ì¸
echo -e "\n3. External APIs"
echo "----------------"
external_apis=("https://api.openai.com/v1/models" "https://api.textIn.com/health")
for api in "${external_apis[@]}"; do
    response=$(curl -s -w "%{http_code}" -o /dev/null "$api")
    if [ "$response" -eq 200 ]; then
        echo "âœ… $api: AVAILABLE"
    else
        echo "âš ï¸ $api: HTTP $response"
    fi
done

# 4. í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo -e "\n4. Environment Variables"
echo "------------------------"
required_vars=("DATABASE_URL" "REDIS_URL" "JWT_SECRET" "OPENAI_API_KEY")
for var in "${required_vars[@]}"; do
    if [ -n "${!var}" ]; then
        echo "âœ… $var: SET"
    else
        echo "âŒ $var: NOT SET"
        exit 1
    fi
done

echo -e "\n=== DEPENDENCIES CHECK COMPLETE ==="
```

### 1.2 ë°±ì—… ìƒì„± (Backup Creation)

#### ìë™ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ (Automated Backup Script)
```bash
#!/bin/bash
# preflight-backup.sh

BACKUP_DIR="/backups/$(date +%Y%m%d_%H%M%S)"
mkdir -p "$BACKUP_DIR"

echo "=== BACKUP CREATION ==="
echo "Backup Directory: $BACKUP_DIR"

# 1. ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
echo "1. Database Backup"
echo "------------------"
pg_dump -h localhost -U kis_user kis_db | gzip > "$BACKUP_DIR/database.sql.gz"
if [ $? -eq 0 ]; then
    echo "âœ… Database backup: SUCCESS"
else
    echo "âŒ Database backup: FAILED"
    exit 1
fi

# 2. ì„¤ì • íŒŒì¼ ë°±ì—…
echo -e "\n2. Configuration Backup"
echo "-----------------------"
config_files=("/etc/nginx/nginx.conf" "/app/config/production.json" "/app/.env")
for file in "${config_files[@]}"; do
    if [ -f "$file" ]; then
        cp "$file" "$BACKUP_DIR/"
        echo "âœ… $file: BACKED UP"
    else
        echo "âš ï¸ $file: FILE NOT FOUND"
    fi
done

# 3. ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ìŠ¤ëƒ…ìƒ·
echo -e "\n3. Application State"
echo "-------------------"
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" > "$BACKUP_DIR/docker_state.txt"
systemctl list-units --type=service --state=running > "$BACKUP_DIR/service_state.txt"

# 4. ë°±ì—… ê²€ì¦
echo -e "\n4. Backup Verification"
echo "----------------------"
backup_size=$(du -sh "$BACKUP_DIR" | cut -f1)
echo "Backup Size: $backup_size"
echo "Backup Location: $BACKUP_DIR"

# ë°±ì—… ë©”íƒ€ë°ì´í„° ìƒì„±
cat > "$BACKUP_DIR/backup_metadata.json" << EOF
{
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "operator": "$(whoami)",
  "environment": "${ENVIRONMENT:-production}",
  "backup_type": "pre-flight",
  "files": [
    "database.sql.gz",
    "nginx.conf",
    "production.json",
    ".env",
    "docker_state.txt",
    "service_state.txt"
  ]
}
EOF

echo "âœ… Backup metadata created"
echo -e "\n=== BACKUP CREATION COMPLETE ==="
```

## PHASE 2: PLAN (ê³„íš ìˆ˜ë¦½)

### 2.1 ì‘ì—… ê³„íš ìˆ˜ë¦½ (Work Planning)

#### ë³€ê²½ ê³„íš í…œí”Œë¦¿ (Change Plan Template)
```yaml
# change_plan_template.yml
change_request:
  id: "CR-2025-001"
  title: "ê²¬ì  AI ëª¨ë¸ ì—…ë°ì´íŠ¸"
  type: "enhancement"  # maintenance, bugfix, enhancement, emergency
  priority: "medium"   # low, medium, high, critical
  
requester:
  name: "ì´ì¶©ì›"
  role: "ëŒ€í‘œì´ì‚¬"
  contact: "ceo@company.com"
  
description:
  summary: "ê²¬ì  AI ëª¨ë¸ì„ v2.3.1ì—ì„œ v2.4.0ìœ¼ë¡œ ì—…ë°ì´íŠ¸"
  business_justification: "ì •í™•ë„ 3% í–¥ìƒ, ì²˜ë¦¬ ì†ë„ 15% ê°œì„ "
  technical_details: |
    - ìƒˆë¡œìš´ í›ˆë ¨ ë°ì´í„°ì…‹ ì ìš©
    - ì•Œê³ ë¦¬ì¦˜ ìµœì í™”
    - API í˜¸í™˜ì„± ìœ ì§€
    
scope:
  systems_affected:
    - "ERP-AI Service"
    - "API Gateway"
    - "ê²¬ì  ìƒì„± ê¸°ëŠ¥"
  
  components_modified:
    - "/app/services/ai-model"
    - "/app/config/model-config.json"
    - "/docker/ai-service/Dockerfile"
    
  data_changes:
    - "AI ëª¨ë¸ ë°”ì´ë„ˆë¦¬ íŒŒì¼ êµì²´"
    - "ì„¤ì • ê°’ ì—…ë°ì´íŠ¸"
    
timeline:
  planned_start: "2025-09-23T02:00:00Z"
  estimated_duration: "2 hours"
  planned_completion: "2025-09-23T04:00:00Z"
  
  milestones:
    - "02:00 - ì‘ì—… ì‹œì‘, íŠ¸ë˜í”½ ì°¨ë‹¨"
    - "02:15 - ìƒˆ ëª¨ë¸ ë°°í¬"
    - "02:45 - í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
    - "03:30 - íŠ¸ë˜í”½ ë³µêµ¬"
    - "04:00 - ì‘ì—… ì™„ë£Œ"
    
risks_and_mitigations:
  - risk: "AI ëª¨ë¸ í˜¸í™˜ì„± ë¬¸ì œ"
    probability: "low"
    impact: "high"
    mitigation: "ì´ì „ ëª¨ë¸ë¡œ ì¦‰ì‹œ ë¡¤ë°±"
    
  - risk: "ì„±ëŠ¥ ì €í•˜"
    probability: "medium"
    impact: "medium"
    mitigation: "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ìë™ ì•ŒëŒ"
    
rollback_plan:
  trigger_conditions:
    - "API ì‘ë‹µ ì‹œê°„ > 5ì´ˆ"
    - "ì—ëŸ¬ìœ¨ > 1%"
    - "AI ì˜ˆì¸¡ ì •í™•ë„ < 90%"
    
  rollback_steps:
    1. "íŠ¸ë˜í”½ ì°¨ë‹¨"
    2. "ì´ì „ ëª¨ë¸ íŒŒì¼ ë³µì›"
    3. "ì„œë¹„ìŠ¤ ì¬ì‹œì‘"
    4. "í…ŒìŠ¤íŠ¸ ì‹¤í–‰"
    5. "íŠ¸ë˜í”½ ë³µêµ¬"
    
  estimated_rollback_time: "30 minutes"
  
approval:
  technical_approval:
    approver: "Lead Architect"
    status: "pending"
    timestamp: null
    
  business_approval:
    approver: "ì´ì¶©ì› (ëŒ€í‘œì´ì‚¬)"
    status: "approved"
    timestamp: "2025-09-22T10:30:00Z"
    
  security_approval:
    approver: "Security Officer"
    status: "approved"
    timestamp: "2025-09-22T11:00:00Z"
```

### 2.2 ë¦¬ìŠ¤í¬ ë¶„ì„ (Risk Analysis)

#### ë¦¬ìŠ¤í¬ í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤ (Risk Assessment Matrix)
```javascript
// risk-assessment.js
const riskMatrix = {
  probability: {
    very_low: 1,    // < 5%
    low: 2,         // 5-15%
    medium: 3,      // 15-40%
    high: 4,        // 40-70%
    very_high: 5    // > 70%
  },
  
  impact: {
    negligible: 1,  // ë¬´ì‹œí•  ìˆ˜ ìˆëŠ” ì˜í–¥
    minor: 2,       // ì•½ê°„ì˜ ë¶ˆí¸
    moderate: 3,    // ê¸°ëŠ¥ ì œí•œ
    major: 4,       // ì„œë¹„ìŠ¤ ì¤‘ë‹¨
    severe: 5       // ì‹¬ê°í•œ ì†ì‹¤
  }
};

function calculateRiskScore(probability, impact) {
  const probScore = riskMatrix.probability[probability];
  const impactScore = riskMatrix.impact[impact];
  return probScore * impactScore;
}

function getRiskLevel(score) {
  if (score <= 4) return 'LOW';
  if (score <= 9) return 'MEDIUM';
  if (score <= 16) return 'HIGH';
  return 'CRITICAL';
}

// ë¦¬ìŠ¤í¬ í‰ê°€ ì˜ˆì‹œ
const risks = [
  {
    id: 'R001',
    description: 'AI ëª¨ë¸ í˜¸í™˜ì„± ë¬¸ì œ',
    probability: 'low',
    impact: 'major',
    mitigation: 'ì´ì „ ëª¨ë¸ë¡œ ì¦‰ì‹œ ë¡¤ë°±',
    owner: 'AI Team Lead'
  },
  {
    id: 'R002',
    description: 'ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨',
    probability: 'very_low',
    impact: 'severe',
    mitigation: 'ë°ì´í„°ë² ì´ìŠ¤ í´ëŸ¬ìŠ¤í„° ë° ì—°ê²° í’€ ì„¤ì •',
    owner: 'DevOps Engineer'
  }
];

// ë¦¬ìŠ¤í¬ ë³´ê³ ì„œ ìƒì„±
function generateRiskReport(risks) {
  return risks.map(risk => {
    const score = calculateRiskScore(risk.probability, risk.impact);
    const level = getRiskLevel(score);
    
    return {
      ...risk,
      score,
      level,
      requires_executive_approval: level === 'CRITICAL' || level === 'HIGH'
    };
  });
}
```

## PHASE 3: ACT (ì‹¤í–‰)

### 3.1 ë³€ê²½ ì‹¤í–‰ (Change Execution)

#### ë°°í¬ ìë™í™” ìŠ¤í¬ë¦½íŠ¸ (Deployment Automation Script)
```bash
#!/bin/bash
# deployment-script.sh

set -e  # ì—ëŸ¬ ë°œìƒ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨

DEPLOYMENT_ID="DEPLOY-$(date +%Y%m%d-%H%M%S)"
LOG_FILE="/var/log/deployments/${DEPLOYMENT_ID}.log"
SLACK_WEBHOOK="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"

# ë¡œê¹… í•¨ìˆ˜
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

# Slack ì•Œë¦¼ í•¨ìˆ˜
slack_notify() {
    local message="$1"
    local color="${2:-good}"
    
    curl -X POST -H 'Content-type: application/json' \
        --data "{\"attachments\":[{\"color\":\"$color\",\"text\":\"$message\"}]}" \
        "$SLACK_WEBHOOK"
}

log "=== DEPLOYMENT START: $DEPLOYMENT_ID ==="
slack_notify "ğŸš€ Deployment started: $DEPLOYMENT_ID"

# 1. íŠ¸ë˜í”½ ì°¨ë‹¨
log "1. Blocking traffic..."
nginx -s reload -c /etc/nginx/maintenance.conf
sleep 10

# 2. ì„œë¹„ìŠ¤ ì¤‘ì§€
log "2. Stopping services..."
systemctl stop estimator-service
systemctl stop erp-ai-service

# 3. ë°±ì—… ìƒì„±
log "3. Creating deployment backup..."
./scripts/preflight-backup.sh

# 4. ìƒˆ ë²„ì „ ë°°í¬
log "4. Deploying new version..."
docker pull kis-core/estimator:latest
docker pull kis-core/erp-ai:latest

# 5. ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ (í•„ìš”ì‹œ)
log "5. Running database migrations..."
if [ -f "migrations/pending.sql" ]; then
    psql -h localhost -U kis_user -d kis_db -f migrations/pending.sql
    log "Database migrations completed"
else
    log "No pending migrations"
fi

# 6. ì„œë¹„ìŠ¤ ì‹œì‘
log "6. Starting services..."
systemctl start estimator-service
systemctl start erp-ai-service

# 7. í—¬ìŠ¤ ì²´í¬
log "7. Health check..."
sleep 30

health_check() {
    local service_url="$1"
    local max_attempts=10
    local attempt=1
    
    while [ $attempt -le $max_attempts ]; do
        if curl -f -s "$service_url/health" > /dev/null; then
            log "âœ… $service_url: HEALTHY"
            return 0
        fi
        log "â³ $service_url: Attempt $attempt/$max_attempts"
        sleep 10
        ((attempt++))
    done
    
    log "âŒ $service_url: UNHEALTHY after $max_attempts attempts"
    return 1
}

# ì„œë¹„ìŠ¤ í—¬ìŠ¤ ì²´í¬
if health_check "http://localhost:3001" && health_check "http://localhost:8000"; then
    # 8. íŠ¸ë˜í”½ ë³µêµ¬
    log "8. Restoring traffic..."
    nginx -s reload -c /etc/nginx/production.conf
    
    log "=== DEPLOYMENT SUCCESS: $DEPLOYMENT_ID ==="
    slack_notify "âœ… Deployment successful: $DEPLOYMENT_ID"
else
    log "=== DEPLOYMENT FAILED: $DEPLOYMENT_ID ==="
    log "Initiating rollback..."
    
    ./scripts/rollback.sh
    slack_notify "âŒ Deployment failed: $DEPLOYMENT_ID. Rollback initiated." "danger"
    exit 1
fi
```

### 3.2 ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ (Real-time Monitoring)

#### ë°°í¬ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ (Deployment Monitoring Dashboard)
```javascript
// monitoring-dashboard.js
const monitoringMetrics = {
  // ì£¼ìš” ì§€í‘œ ì •ì˜
  criticalMetrics: [
    'api_response_time_p95',
    'error_rate',
    'active_connections',
    'cpu_utilization',
    'memory_usage'
  ],
  
  // ì„ê³„ì¹˜ ì„¤ì •
  thresholds: {
    api_response_time_p95: 2100,
    error_rate: 0.01,
    active_connections: 1000,
    cpu_utilization: 80,
    memory_usage: 85
  },
  
  // ëª¨ë‹ˆí„°ë§ ê°„ê²©
  intervals: {
    critical: 30,    // 30ì´ˆ
    normal: 300,     // 5ë¶„
    extended: 3600   // 1ì‹œê°„
  }
};

class DeploymentMonitor {
  constructor(deploymentId) {
    this.deploymentId = deploymentId;
    this.alerts = [];
    this.metrics = {};
    this.isMonitoring = false;
  }
  
  async startMonitoring() {
    this.isMonitoring = true;
    console.log(`ğŸ” Starting deployment monitoring for ${this.deploymentId}`);
    
    // í¬ë¦¬í‹°ì»¬ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ (30ì´ˆ ê°„ê²©)
    this.criticalInterval = setInterval(async () => {
      await this.collectCriticalMetrics();
      await this.checkThresholds();
    }, monitoringMetrics.intervals.critical * 1000);
    
    // í™•ì¥ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ (5ë¶„ ê°„ê²©)
    this.extendedInterval = setInterval(async () => {
      await this.collectExtendedMetrics();
      await this.generateReport();
    }, monitoringMetrics.intervals.normal * 1000);
  }
  
  async collectCriticalMetrics() {
    try {
      // API ì‘ë‹µ ì‹œê°„
      const apiMetrics = await this.getApiMetrics();
      this.metrics.api_response_time_p95 = apiMetrics.p95;
      this.metrics.error_rate = apiMetrics.errorRate;
      
      // ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤
      const systemMetrics = await this.getSystemMetrics();
      this.metrics.cpu_utilization = systemMetrics.cpu;
      this.metrics.memory_usage = systemMetrics.memory;
      
      // ì—°ê²° ìˆ˜
      const connectionMetrics = await this.getConnectionMetrics();
      this.metrics.active_connections = connectionMetrics.active;
      
    } catch (error) {
      console.error('Failed to collect metrics:', error);
      this.addAlert('CRITICAL', 'Metric collection failed', error.message);
    }
  }
  
  async checkThresholds() {
    const violations = [];
    
    for (const [metric, value] of Object.entries(this.metrics)) {
      const threshold = monitoringMetrics.thresholds[metric];
      if (threshold && value > threshold) {
        violations.push({
          metric,
          value,
          threshold,
          severity: this.getSeverity(metric, value, threshold)
        });
      }
    }
    
    if (violations.length > 0) {
      await this.handleThresholdViolations(violations);
    }
  }
  
  async handleThresholdViolations(violations) {
    const criticalViolations = violations.filter(v => v.severity === 'CRITICAL');
    
    if (criticalViolations.length > 0) {
      console.error('ğŸš¨ CRITICAL THRESHOLD VIOLATIONS:', criticalViolations);
      
      // ìë™ ë¡¤ë°± íŠ¸ë¦¬ê±°
      if (this.shouldAutoRollback(criticalViolations)) {
        console.log('ğŸ”„ Triggering automatic rollback...');
        await this.triggerRollback();
      }
      
      // ì¦‰ì‹œ ì•Œë¦¼
      await this.sendCriticalAlert(criticalViolations);
    }
  }
  
  shouldAutoRollback(violations) {
    // ìë™ ë¡¤ë°± ì¡°ê±´
    const autoRollbackTriggers = [
      'api_response_time_p95',
      'error_rate'
    ];
    
    return violations.some(v => 
      autoRollbackTriggers.includes(v.metric) && 
      v.value > v.threshold * 1.5  // ì„ê³„ì¹˜ì˜ 150% ì´ˆê³¼
    );
  }
  
  async generateReport() {
    const report = {
      deploymentId: this.deploymentId,
      timestamp: new Date().toISOString(),
      metrics: this.metrics,
      alerts: this.alerts,
      status: this.getOverallStatus()
    };
    
    console.log('ğŸ“Š Deployment monitoring report:', report);
    return report;
  }
  
  stopMonitoring() {
    this.isMonitoring = false;
    if (this.criticalInterval) clearInterval(this.criticalInterval);
    if (this.extendedInterval) clearInterval(this.extendedInterval);
    console.log('â¹ï¸ Monitoring stopped');
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
const monitor = new DeploymentMonitor('DEPLOY-20250922-143000');
await monitor.startMonitoring();

// ë°°í¬ ì™„ë£Œ í›„ ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨
setTimeout(() => {
  monitor.stopMonitoring();
}, 30 * 60 * 1000); // 30ë¶„ í›„
```

## PHASE 4: TEST (í…ŒìŠ¤íŠ¸)

### 4.1 ë°°í¬ í›„ í…ŒìŠ¤íŠ¸ (Post-deployment Testing)

#### ìë™í™”ëœ ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ (Automated Smoke Tests)
```javascript
// smoke-tests.js
const SmokeTests = {
  async runAllTests() {
    const results = {
      passed: 0,
      failed: 0,
      tests: []
    };
    
    const testSuites = [
      this.testCriticalPaths,
      this.testApiEndpoints,
      this.testDatabaseConnections,
      this.testExternalIntegrations,
      this.testPerformanceBaseline
    ];
    
    for (const testSuite of testSuites) {
      try {
        const suiteResults = await testSuite.call(this);
        results.tests.push(...suiteResults);
        results.passed += suiteResults.filter(t => t.status === 'PASS').length;
        results.failed += suiteResults.filter(t => t.status === 'FAIL').length;
      } catch (error) {
        console.error('Test suite failed:', error);
        results.failed++;
      }
    }
    
    return results;
  },
  
  async testCriticalPaths() {
    console.log('ğŸ§ª Testing critical paths...');
    const tests = [];
    
    // 1. ì‚¬ìš©ì ì¸ì¦ í…ŒìŠ¤íŠ¸
    tests.push(await this.testUserAuthentication());
    
    // 2. ê²¬ì  ìƒì„± í…ŒìŠ¤íŠ¸
    tests.push(await this.testEstimateCreation());
    
    // 3. AI ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    tests.push(await this.testAIPrediction());
    
    return tests;
  },
  
  async testUserAuthentication() {
    try {
      const response = await fetch('/api/v1/auth/login', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          email: 'test@company.com',
          password: 'test123'
        })
      });
      
      if (response.ok) {
        const data = await response.json();
        return {
          name: 'User Authentication',
          status: 'PASS',
          duration: Date.now() - startTime,
          details: 'Login successful, token received'
        };
      } else {
        throw new Error(`HTTP ${response.status}`);
      }
    } catch (error) {
      return {
        name: 'User Authentication',
        status: 'FAIL',
        duration: Date.now() - startTime,
        error: error.message
      };
    }
  },
  
  async testEstimateCreation() {
    const startTime = Date.now();
    try {
      const response = await fetch('/api/v1/estimate', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': 'Bearer ' + await this.getTestToken()
        },
        body: JSON.stringify({
          customerId: 'test_customer',
          projectName: 'Smoke Test Project',
          estimateItems: [{
            category: 'HARDWARE',
            itemCode: 'TEST_001',
            quantity: 1
          }]
        })
      });
      
      if (response.ok) {
        const data = await response.json();
        return {
          name: 'Estimate Creation',
          status: 'PASS',
          duration: Date.now() - startTime,
          details: `Estimate ${data.estimateId} created successfully`
        };
      } else {
        throw new Error(`HTTP ${response.status}`);
      }
    } catch (error) {
      return {
        name: 'Estimate Creation',
        status: 'FAIL',
        duration: Date.now() - startTime,
        error: error.message
      };
    }
  },
  
  async testApiEndpoints() {
    console.log('ğŸŒ Testing API endpoints...');
    const endpoints = [
      { path: '/api/v1/health', method: 'GET', expected: 200 },
      { path: '/api/v1/estimates', method: 'GET', expected: 200 },
      { path: '/api/v1/templates', method: 'GET', expected: 200 }
    ];
    
    const tests = [];
    for (const endpoint of endpoints) {
      tests.push(await this.testEndpoint(endpoint));
    }
    
    return tests;
  },
  
  async testPerformanceBaseline() {
    console.log('âš¡ Testing performance baseline...');
    const tests = [];
    
    // API ì‘ë‹µ ì‹œê°„ í…ŒìŠ¤íŠ¸
    const startTime = Date.now();
    try {
      const response = await fetch('/api/v1/health');
      const duration = Date.now() - startTime;
      
      tests.push({
        name: 'API Response Time',
        status: duration <= 2100 ? 'PASS' : 'FAIL',
        duration: duration,
        details: `Response time: ${duration}ms (threshold: 2100ms)`
      });
    } catch (error) {
      tests.push({
        name: 'API Response Time',
        status: 'FAIL',
        error: error.message
      });
    }
    
    return tests;
  }
};

// ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
async function runSmokeTests() {
  console.log('ğŸš€ Starting smoke tests...');
  const results = await SmokeTests.runAllTests();
  
  console.log('ğŸ“Š Smoke test results:');
  console.log(`  Passed: ${results.passed}`);
  console.log(`  Failed: ${results.failed}`);
  console.log(`  Total: ${results.tests.length}`);
  
  if (results.failed > 0) {
    console.error('âŒ Smoke tests failed!');
    process.exit(1);
  } else {
    console.log('âœ… All smoke tests passed!');
  }
  
  return results;
}
```

### 4.2 ì„±ëŠ¥ íšŒê·€ í…ŒìŠ¤íŠ¸ (Performance Regression Testing)

#### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ (Performance Benchmark Test)
```bash
#!/bin/bash
# performance-regression-test.sh

echo "=== PERFORMANCE REGRESSION TEST ==="
echo "Timestamp: $(date -u)"

# í…ŒìŠ¤íŠ¸ ì„¤ì •
TARGET_URL="https://api.kis-core.com"
CONCURRENT_USERS=50
TEST_DURATION=300  # 5ë¶„
ACCEPTABLE_P95=2100  # ms

# 1. ë¶€í•˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
echo "1. Running load test..."
echo "Target: $TARGET_URL"
echo "Concurrent Users: $CONCURRENT_USERS"
echo "Duration: ${TEST_DURATION}s"

# k6ë¥¼ ì´ìš©í•œ ë¶€í•˜ í…ŒìŠ¤íŠ¸
k6 run --vus $CONCURRENT_USERS --duration ${TEST_DURATION}s - <<EOF
import http from 'k6/http';
import { check, sleep } from 'k6';

export default function() {
  // í—¬ìŠ¤ ì²´í¬
  let response = http.get('${TARGET_URL}/api/v1/health');
  check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 2100ms': (r) => r.timings.duration < 2100,
  });
  
  // ê²¬ì  ëª©ë¡ ì¡°íšŒ
  response = http.get('${TARGET_URL}/api/v1/estimates', {
    headers: { 'Authorization': 'Bearer test-token' }
  });
  check(response, {
    'estimates status is 200': (r) => r.status === 200,
  });
  
  sleep(1);
}

export function handleSummary(data) {
  return {
    '/tmp/k6-results.json': JSON.stringify(data),
  };
}
EOF

# 2. ê²°ê³¼ ë¶„ì„
echo -e "\n2. Analyzing results..."
RESULTS_FILE="/tmp/k6-results.json"

if [ -f "$RESULTS_FILE" ]; then
    # JSON ê²°ê³¼ íŒŒì‹±
    p95_response_time=$(jq -r '.metrics.http_req_duration.values.p95' "$RESULTS_FILE")
    avg_response_time=$(jq -r '.metrics.http_req_duration.values.avg' "$RESULTS_FILE")
    error_rate=$(jq -r '.metrics.http_req_failed.values.rate' "$RESULTS_FILE")
    
    echo "Results:"
    echo "  Average Response Time: ${avg_response_time}ms"
    echo "  P95 Response Time: ${p95_response_time}ms"
    echo "  Error Rate: ${error_rate}%"
    
    # ì„±ëŠ¥ ê¸°ì¤€ í™•ì¸
    if (( $(echo "$p95_response_time > $ACCEPTABLE_P95" | bc -l) )); then
        echo "âŒ PERFORMANCE REGRESSION: P95 response time exceeds threshold"
        echo "   Current: ${p95_response_time}ms"
        echo "   Threshold: ${ACCEPTABLE_P95}ms"
        exit 1
    else
        echo "âœ… PERFORMANCE TEST PASSED"
    fi
    
    # ì—ëŸ¬ìœ¨ í™•ì¸
    if (( $(echo "$error_rate > 0.01" | bc -l) )); then
        echo "âŒ ERROR RATE TOO HIGH: ${error_rate}%"
        exit 1
    fi
    
else
    echo "âŒ Performance test results not found"
    exit 1
fi

echo -e "\n=== PERFORMANCE REGRESSION TEST COMPLETE ==="
```

## PHASE 5: REPORT (ë³´ê³ )

### 5.1 ê²°ê³¼ ë¶„ì„ ë° ë³´ê³  (Result Analysis & Reporting)

#### ìë™ ë°°í¬ ë³´ê³ ì„œ ìƒì„± (Automated Deployment Report Generation)
```javascript
// deployment-report-generator.js
class DeploymentReportGenerator {
  constructor(deploymentId) {
    this.deploymentId = deploymentId;
    this.startTime = new Date();
    this.endTime = null;
    this.status = 'IN_PROGRESS';
    this.metrics = {};
    this.tests = [];
    this.issues = [];
  }
  
  async generateReport() {
    this.endTime = new Date();
    const duration = this.endTime - this.startTime;
    
    const report = {
      deployment: {
        id: this.deploymentId,
        startTime: this.startTime.toISOString(),
        endTime: this.endTime.toISOString(),
        duration: this.formatDuration(duration),
        status: this.status,
        operator: process.env.USER || 'system'
      },
      
      summary: {
        overall_status: this.getOverallStatus(),
        critical_issues: this.issues.filter(i => i.severity === 'CRITICAL').length,
        performance_status: this.getPerformanceStatus(),
        test_results: this.getTestSummary()
      },
      
      metrics: {
        pre_deployment: await this.getPreDeploymentMetrics(),
        post_deployment: await this.getPostDeploymentMetrics(),
        comparison: this.compareMetrics()
      },
      
      tests: {
        smoke_tests: this.tests.filter(t => t.type === 'smoke'),
        regression_tests: this.tests.filter(t => t.type === 'regression'),
        performance_tests: this.tests.filter(t => t.type === 'performance')
      },
      
      issues: this.issues,
      
      rollback: {
        executed: this.status === 'ROLLED_BACK',
        reason: this.rollbackReason || null,
        duration: this.rollbackDuration || null
      },
      
      recommendations: this.generateRecommendations()
    };
    
    return report;
  }
  
  generate12LineQCSummary() {
    const timestamp = new Date().toISOString();
    const duration = this.endTime ? this.formatDuration(this.endTime - this.startTime) : 'In Progress';
    const smokeTestsPassed = this.tests.filter(t => t.type === 'smoke' && t.status === 'PASS').length;
    const totalSmokeTests = this.tests.filter(t => t.type === 'smoke').length;
    const criticalIssues = this.issues.filter(i => i.severity === 'CRITICAL').length;
    
    return `
KIS_CORE_V3 Deployment Report - ${timestamp}
============================================
Deployment ID: ${this.deploymentId}
Status: ${this.status} (Duration: ${duration})
Smoke Tests: ${smokeTestsPassed}/${totalSmokeTests} passed
Performance: ${this.getPerformanceStatus()}
Critical Issues: ${criticalIssues}
API Health: ${this.metrics.api_health || 'Unknown'}
Database: ${this.metrics.db_health || 'Unknown'}
Cache: ${this.metrics.cache_health || 'Unknown'}
Error Rate: ${this.metrics.error_rate || 'Unknown'}%
Response Time P95: ${this.metrics.response_time_p95 || 'Unknown'}ms
============================================
Overall: ${this.getOverallStatus()}
    `.trim();
  }
  
  async sendReport() {
    const report = await this.generateReport();
    const summary = this.generate12LineQCSummary();
    
    // Slack ì•Œë¦¼
    await this.sendSlackNotification(summary, report);
    
    // ì´ë©”ì¼ ë³´ê³ ì„œ (ì¤‘ìš”í•œ ë°°í¬ë§Œ)
    if (this.status === 'FAILED' || this.issues.length > 0) {
      await this.sendEmailReport(report);
    }
    
    // ë°°í¬ íˆìŠ¤í† ë¦¬ ì €ì¥
    await this.saveToDatabase(report);
    
    // íŒŒì¼ë¡œ ì €ì¥
    const reportFile = `/var/log/deployments/${this.deploymentId}-report.json`;
    fs.writeFileSync(reportFile, JSON.stringify(report, null, 2));
    
    return report;
  }
  
  async sendSlackNotification(summary, report) {
    const color = this.getSlackColor();
    const emoji = this.status === 'SUCCESS' ? 'âœ…' : 
                  this.status === 'FAILED' ? 'âŒ' : 
                  this.status === 'ROLLED_BACK' ? 'ğŸ”„' : 'âš ï¸';
    
    const payload = {
      attachments: [{
        color: color,
        title: `${emoji} Deployment ${this.status}: ${this.deploymentId}`,
        text: '```\n' + summary + '\n```',
        fields: [
          {
            title: 'Duration',
            value: this.formatDuration(this.endTime - this.startTime),
            short: true
          },
          {
            title: 'Operator',
            value: process.env.USER || 'system',
            short: true
          }
        ],
        footer: 'KIS_CORE_V3 Deployment System',
        ts: Math.floor(Date.now() / 1000)
      }]
    };
    
    const webhook = process.env.SLACK_WEBHOOK_URL;
    if (webhook) {
      await fetch(webhook, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(payload)
      });
    }
  }
  
  generateRecommendations() {
    const recommendations = [];
    
    // ì„±ëŠ¥ ê¸°ë°˜ ì¶”ì²œ
    if (this.metrics.response_time_p95 > 1500) {
      recommendations.push({
        type: 'PERFORMANCE',
        priority: 'MEDIUM',
        description: 'API ì‘ë‹µ ì‹œê°„ì´ 1.5ì´ˆë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ìºì‹œ ì„¤ì • ë° ì¿¼ë¦¬ ìµœì í™”ë¥¼ ê²€í† í•˜ì„¸ìš”.'
      });
    }
    
    // ì—ëŸ¬ìœ¨ ê¸°ë°˜ ì¶”ì²œ
    if (this.metrics.error_rate > 0.005) {
      recommendations.push({
        type: 'RELIABILITY',
        priority: 'HIGH',
        description: 'ì—ëŸ¬ìœ¨ì´ 0.5%ë¥¼ ì´ˆê³¼í•©ë‹ˆë‹¤. ì—ëŸ¬ ë¡œê·¸ë¥¼ ë¶„ì„í•˜ê³  ì›ì¸ì„ íŒŒì•…í•˜ì„¸ìš”.'
      });
    }
    
    // í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ ê¸°ë°˜ ì¶”ì²œ
    const failedTests = this.tests.filter(t => t.status === 'FAIL');
    if (failedTests.length > 0) {
      recommendations.push({
        type: 'TESTING',
        priority: 'HIGH',
        description: `${failedTests.length}ê°œì˜ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë°°í¬ ì „ì— í•´ê²°í•˜ì„¸ìš”.`
      });
    }
    
    return recommendations;
  }
}

// ì‚¬ìš© ì˜ˆì‹œ
const reporter = new DeploymentReportGenerator('DEPLOY-20250922-143000');
// ... ë°°í¬ ê³¼ì •ì—ì„œ ë©”íŠ¸ë¦­ ë° í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìˆ˜ì§‘ ...
const report = await reporter.sendReport();
console.log('ğŸ“„ Deployment report sent:', report.deployment.id);
```

### 5.2 ì§€ì†ì  ê°œì„  (Continuous Improvement)

#### ë°°í¬ í›„ íšŒê³  í…œí”Œë¦¿ (Post-deployment Retrospective Template)
```yaml
# deployment-retrospective-template.yml
retrospective:
  deployment_id: "DEPLOY-20250922-143000"
  date: "2025-09-22"
  participants:
    - "ì´ì¶©ì› (ëŒ€í‘œì´ì‚¬)"
    - "Lead Architect"
    - "DevOps Engineer"
    - "QA Lead"
    
what_went_well:
  - "ë°°í¬ ìë™í™”ê°€ ì˜ˆìƒëŒ€ë¡œ ì‘ë™í•¨"
  - "ëª¨ë“  ìŠ¤ëª¨í¬ í…ŒìŠ¤íŠ¸ í†µê³¼"
  - "ë¡¤ë°± ê³„íšì´ ëª…í™•í•˜ê²Œ ì •ì˜ë¨"
  - "ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ì´ íš¨ê³¼ì ì´ì—ˆìŒ"
  
what_went_wrong:
  - "ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ì—ì„œ ì¼ì‹œì  ì‘ë‹µ ì§€ì—° ë°œìƒ"
  - "Slack ì•Œë¦¼ì´ 10ë¶„ ì§€ì—°ë¨"
  - "ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ì´ ì˜ˆìƒë³´ë‹¤ ì˜¤ë˜ ê±¸ë¦¼"
  
action_items:
  - id: "AI-001"
    description: "ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ê°œì„ "
    assignee: "Performance Engineer"
    due_date: "2025-09-29"
    priority: "MEDIUM"
    
  - id: "AI-002"
    description: "ì•Œë¦¼ ì‹œìŠ¤í…œ ì•ˆì •ì„± ê°œì„ "
    assignee: "DevOps Engineer"
    due_date: "2025-09-25"
    priority: "HIGH"
    
  - id: "AI-003"
    description: "ë°ì´í„°ë² ì´ìŠ¤ ë§ˆì´ê·¸ë ˆì´ì…˜ ì„±ëŠ¥ ìµœì í™”"
    assignee: "Database Administrator"
    due_date: "2025-10-01"
    priority: "LOW"
    
lessons_learned:
  - "ë°°í¬ ì „ ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸ ì„¤ì •ì´ ì¤‘ìš”í•¨"
  - "ì•Œë¦¼ ì‹œìŠ¤í…œì˜ ì´ì¤‘í™” í•„ìš”"
  - "ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œê°„ ì˜ˆì¸¡ ì •í™•ì„± í–¥ìƒ í•„ìš”"
  
process_improvements:
  - "ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ì— ì„±ëŠ¥ ë² ì´ìŠ¤ë¼ì¸ ì¶”ê°€"
  - "ì•Œë¦¼ ì‹œìŠ¤í…œ redundancy êµ¬ì„±"
  - "ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œê°„ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ"
  
metrics_analysis:
  deployment_duration:
    planned: "2 hours"
    actual: "2.5 hours"
    variance: "+25%"
    
  downtime:
    planned: "15 minutes"
    actual: "8 minutes"
    variance: "-47%"
    
  test_coverage:
    smoke_tests: "100%"
    regression_tests: "95%"
    performance_tests: "90%"
    
next_deployment_focus:
  - "ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê°•í™”"
  - "ì•Œë¦¼ ì‹œìŠ¤í…œ ì•ˆì •ì„±"
  - "ë§ˆì´ê·¸ë ˆì´ì…˜ ìµœì í™”"
```

---
*ë¬¸ì„œ ë²„ì „: 1.0*  
*ìµœì¢… ìˆ˜ì •: 2025-09-22*  
*ìŠ¹ì¸ì: ì´ì¶©ì› (ëŒ€í‘œì´ì‚¬)*